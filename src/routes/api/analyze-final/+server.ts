import { GoogleGenerativeAI } from "@google/generative-ai";
import { GEMINI_API_KEY } from '$env/static/private';
import { json } from '@sveltejs/kit';
import { adminAuth, adminDb } from '$lib/server/firebase-admin';

export const config = {
    maxDuration: 60
};

export const POST = async ({ request }) => {
    const genAI = new GoogleGenerativeAI(GEMINI_API_KEY);
    try {
        const { subjectName, analyses, customInstructions } = await request.json();

        // --- Auth & Data Check ---
        let uid: string | null = null;
        let userData: any = null;
        let isPremium = false;
        let isUltimate = false;

        console.log(`ðŸš€ [Analyze-Final] Start processing for subject: ${subjectName}`);

        const authHeader = request.headers.get('Authorization');
        if (authHeader && authHeader.startsWith('Bearer ')) {
            try {
                const idToken = authHeader.split('Bearer ')[1];
                const decodedToken = await adminAuth.verifyIdToken(idToken);
                uid = decodedToken.uid;
                console.log(`âœ… [Analyze-Final] Auth Verified for UID: ${uid}`);

                // Fetch latest user data for plan verification
                try {
                    const userDoc = await adminDb.collection('users').doc(uid).get();
                    if (userDoc.exists) {
                        userData = userDoc.data();
                        const plan = String(userData?.plan || '').trim().toLowerCase();
                        isPremium = ['premium', 'ultimate', 'season', 'pro'].includes(plan);
                        isUltimate = plan === 'ultimate';
                        console.log(`ðŸ’Ž [Analyze-Final] Plan: ${plan} (Premium: ${isPremium}, Ultimate: ${isUltimate})`);
                    }
                } catch (dbError) {
                    console.warn("âš ï¸ [Analyze-Final] Failed to fetch user data:", dbError);
                }
            } catch (e) {
                console.warn('âš ï¸ [Analyze-Final] Auth token verification failed:', e);
            }
        }

        if (!analyses || analyses.length === 0) {
            console.error("âŒ [Analyze-Final] No analysis data provided");
            return json({ error: "No analysis data provided" }, { status: 400 });
        }

        // --- Hybrid Summary Logic ---

        // 1. Estimate total length and chunk if necessary
        const totalLength = analyses.reduce((acc: number, cur: any) => acc + cur.analysis.length, 0);
        const CHUNK_THRESHOLD = 30000; // Approx 15k-20k tokens for Japanese

        let finalContext = "";

        if (totalLength > CHUNK_THRESHOLD) {
            console.log(`[Hybrid Summary] Large input detected (${totalLength} chars). Splitting into chunks...`);

            // Split analyses into chunks (2-4 groups)
            const numChunks = Math.min(4, Math.ceil(totalLength / CHUNK_THRESHOLD));
            const chunks: any[][] = Array.from({ length: numChunks }, () => []);
            let currentChunkIndex = 0;
            let currentChunkLength = 0;

            analyses.forEach((item: any) => {
                if (currentChunkLength > CHUNK_THRESHOLD && currentChunkIndex < numChunks - 1) {
                    currentChunkIndex++;
                    currentChunkLength = 0;
                }
                chunks[currentChunkIndex].push(item);
                currentChunkLength += item.analysis.length;
            });

            // Stage 1: Parallel Intermediate Summaries (Gemini 2.0 Flash)
            const flashModel = genAI.getGenerativeModel({ model: "gemini-2.0-flash" });

            const intermediateSummaries = await Promise.all(chunks.map(async (chunk, i) => {
                let chunkContext = `Chunk ${i + 1}:\n`;
                chunk.forEach((item, j) => {
                    chunkContext += `Lecture ${j + 1}: ${item.title}\n${item.analysis}\n\n`;
                });

                const intermediatePrompt = `
ã‚ãªãŸã¯å­¦è¡“ãƒ‡ãƒ¼ã‚¿ã®åœ§ç¸®å°‚é–€AIã§ã™ã€‚ä»¥ä¸‹ã®è¬›ç¾©ãƒ‡ãƒ¼ã‚¿ã‚’ã€**é‡è¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã¨è«–ç†æ§‹é€ ã‚’ç¶­æŒã—ãŸã¾ã¾ 1/10 ã®é•·ã•ã«è¦ç´„**ã—ã¦ãã ã•ã„ã€‚

**ã€åŽ³å®ˆãƒ«ãƒ¼ãƒ«ã€‘**
- **å›ºæœ‰åè©žã€å°‚é–€ç”¨èªžã€æ—¥ä»˜ã€è©¦é¨“ã«é–¢ã™ã‚‹è¨€åŠ**ã¯ã€çµ¶å¯¾ã«å‰Šã‚‰ãšã«å…¨ã¦æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚
- å†—é•·ãªè£…é£¾ã‚’çœãã€äº‹å®Ÿã«åŸºã¥ã„ãŸæƒ…å ±å¯†åº¦ã‚’æœ€å¤§åŒ–ã—ã¦ãã ã•ã„ã€‚
- å‡ºåŠ›ã¯æ§‹é€ åŒ–ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆå½¢å¼ï¼ˆç®‡æ¡æ›¸ãæŽ¨å¥¨ï¼‰ã¨ã—ã¦ãã ã•ã„ã€‚

ãƒ‡ãƒ¼ã‚¿:
${chunkContext}
`;
                const result = await flashModel.generateContent(intermediatePrompt);
                return result.response.text();
            }));

            finalContext = intermediateSummaries.join("\n\n--- Next Section ---\n\n");
        } else {
            // Standard small processing
            let context = `Subject: ${subjectName}\n\n`;
            analyses.forEach((item: any, index: number) => {
                context += `--- Lecture ${index + 1}: ${item.title} ---\n`;
                context += `Summary/Notes: ${item.analysis.slice(0, 5000)}\n\n`;
            });
            finalContext = context;
        }

        const systemPrompt = `
ã‚ãªãŸã¯ã€å¤§å­¦ç”ŸãŒå˜ä½ã‚’è½ã¨ã•ãªã„ãŸã‚ã®ã€Œæœ€çŸ­ãƒ»æœ€å¼·ã®è©¦é¨“å¯¾ç­–ãƒŽãƒ¼ãƒˆã€ã‚’ä½œæˆã™ã‚‹å°‚é–€AIã§ã™ã€‚æä¾›ã•ã‚ŒãŸè¬›ç¾©ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æžã—ã€ä»¥ä¸‹ã® 4 ã¤ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§æ§‹æˆã•ã‚Œã‚‹å¯¾ç­–ãƒŽãƒ¼ãƒˆã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

**ã€é‡è¦ï¼šå›žç­”ã®ã‚¹ã‚¿ã‚¤ãƒ«ã¨ãƒ«ãƒ¼ãƒ«ã€‘**
1. **### å„è¦‹å‡ºã—ã®ç›´å¾Œã«å¿…ãš1è¡Œã®ç©ºè¡Œã‚’å…¥ã‚Œã‚‹ã“ã¨ã€‚**
2. **è¦æ—¨ï¼ˆå†’é ­ï¼‰ã¯3è¡Œä»¥å†…**ã§å…¨ä½“ã®ãƒã‚¤ãƒ³ãƒˆã‚’è¨˜è¿°ã—ã¦ãã ã•ã„ã€‚
3. **è¦–è¦šçš„ãƒ¡ãƒªãƒãƒª**: é‡è¦ãªçµè«–ã‚„ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã«ã¯ \`> [!IMPORTANT]\` ã¾ãŸã¯å¼•ç”¨ãƒ–ãƒ­ãƒƒã‚¯ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚
4. **æ¯”è¼ƒãƒ»åˆ†é¡ž**: å¯¾æ¯”æ§‹é€ ãŒã‚ã‚‹å ´åˆã¯ã€å¿…ãš Markdown ãƒ†ãƒ¼ãƒ–ãƒ«ï¼ˆãƒ¢ãƒã‚¤ãƒ«é…æ…®ã§ã‚·ãƒ³ãƒ—ãƒ«ã«ï¼‰ã§æ•´ç†ã—ã¦ãã ã•ã„ã€‚
5. **HTMLã‚¿ã‚°ç¦æ­¢**: å…¨ã¦ç´”ç²‹ãª Markdown å½¢å¼ã§è¨˜è¿°ã—ã¦ãã ã•ã„ã€‚

### ã€è¦æ—¨ã€‘

### ã€1. çµ¶å¯¾æš—è¨˜ï¼šè©¦é¨“å‡ºç¾ãƒã‚¤ãƒ³ãƒˆã€‘
è¬›ç¾©å†…ã§ã€Œã“ã“ãŒå‡ºã‚‹ã€ã€Œé‡è¦ã€ã¨æ˜Žç¤ºã•ã‚ŒãŸç®‡æ‰€ã€ã¾ãŸã¯è¤‡æ•°å›žè¨€åŠã•ã‚ŒãŸæ¦‚å¿µã‚’æœ€å„ªå…ˆã§ãƒªã‚¹ãƒˆã‚¢ãƒƒãƒ—ã—ã¦ãã ã•ã„ã€‚

### ã€2. ç”¨èªžæ”»ç•¥ï¼šé‡è¦å˜èªžè¾žå…¸ã€‘
è©¦é¨“ã§å•ã‚ã‚Œã‚„ã™ã„å°‚é–€ç”¨èªžã‚’æŠ½å‡ºã—ã€\`**ç”¨èªžå**: å®šç¾©\` ã®å½¢å¼ã§ç°¡æ½”ã«è¨˜è¼‰ã—ã¦ãã ã•ã„ã€‚

### ã€3. è«–è¿°å¯¾ç­–ï¼šå› æžœé–¢ä¿‚ã®ã¾ã¨ã‚ã€‘
è«–è¿°å•é¡Œã§ãã®ã¾ã¾ä½¿ãˆã‚‹å½¢å¼ã§ã€è«–ç†ã®éª¨çµ„ã¿ã‚’æ•´ç†ã—ã¦ãã ã•ã„ã€‚

### ã€4. AIäºˆæƒ³å•é¡Œï¼ˆè§£ç­”ãƒ»è§£èª¬ä»˜ãï¼‰ã€‘
è©¦é¨“ã§æƒ³å®šã•ã‚Œã‚‹å•é¡Œã‚’ 3ã€œ5 å•ä½œæˆã—ã¦ãã ã•ã„ã€‚
- å…¨ã¦ã®å•é¡Œã«ã€Œæ­£è§£ã€ã¨ã€Œè§£èª¬ã€ã‚’å¿…ãšä»˜ã‘ã‚‹ã“ã¨ã€‚
- å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒžãƒƒãƒˆï¼š
  å•é¡Œ: [å•ã„]
  æ­£è§£: [ç­”ãˆ]
  è§£èª¬: [æ ¹æ‹ ]

${customInstructions ? `\nãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®è¿½åŠ æŒ‡ç¤º:\n${customInstructions}\n` : ""}

Context (Processed Summaries):
${finalContext}
`;

        // Automatic model selection if needed
        let modelName = "gemini-2.0-flash";
        /* 
        // If using v1beta and dynamic selection is desired:
        try {
            const models = await genAI.listModels();
            const latest = models.find(m => m.name.includes("flash"))?.name;
            if (latest) modelName = latest.split("/").pop() || modelName;
        } catch (e) {
            console.warn("Failed to list models, using fallback:", modelName);
        }
        */

        // Stage 2: Final Integration (Gemini 2.0 Flash)
        const finalModel = genAI.getGenerativeModel({
            model: "gemini-2.0-flash", // Replaced Pro with Flash to avoid 404 and standardize
        });

        const result = await finalModel.generateContent(systemPrompt);
        const responseText = result.response.text();

        return json({ result: responseText });

    } catch (e: any) {
        console.error("ðŸš¨ [Analyze-Final] Critical Error:", e);
        console.error("Stack:", e.stack);
        return json({
            error: "Failed to generate final summary",
            details: e.message,
            debug: process.env.NODE_ENV === 'development' ? e.stack : undefined
        }, { status: 500 });
    }
};
